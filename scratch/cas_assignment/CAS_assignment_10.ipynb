{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Overview\n",
    "In this assignment you will implement part of the framework for closed-loop neural control as discussed in the lecture, and reproduce some of the key results. The assignment is structured in three parts, corresponding to the three components of the brain-machine-environment interaction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "from mxnet.ndarray import NDArray\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import solve_discrete_are\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper code\n",
    "The code below does not contain anything concptually new; it re-implements some of the functions you have worked with in previous assignments, such as recurrent neural networks (RNNs), linear quadratic regularizer (LQR), functions to run the double integrator system, and visualization tools. Feel free to use your own code if it is more convenient."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class RNN(mx.gluon.Block):\n",
    "    \"\"\"Single-layer vanilla RNN with fully-connected decoder.\"\"\"\n",
    "    def __init__(self, num_hidden=1, num_outputs=1, num_inputs=1,\n",
    "                 activation_rnn=None, activation_decoder=None, **kwargs):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # The mxnet RNN class does not support linear activations, so we\n",
    "        # implement it using a LeakyReLU with slope 1.\n",
    "        if activation_rnn == 'linear':\n",
    "            activation_rnn = mx.gluon.nn.LeakyReLU(1)\n",
    "        with self.name_scope():\n",
    "            self.rnn = mx.gluon.rnn.RNNCell(num_hidden,\n",
    "                                            activation_rnn,\n",
    "                                            input_size=num_inputs,\n",
    "                                            prefix='rnn_')\n",
    "            self.decoder = mx.gluon.nn.Dense(num_outputs,\n",
    "                                             activation_decoder,\n",
    "                                             in_units=num_hidden,\n",
    "                                             prefix='decoder_')\n",
    "        self.initialize()\n",
    "\n",
    "    def forward(self, inputs: NDArray, states: NDArray) \\\n",
    "            -> Tuple[NDArray, NDArray]:\n",
    "        \"\"\"Perform forward pass of model.\"\"\"\n",
    "\n",
    "        # Add a dummy batch dimension of size 1.\n",
    "        inputs = mx.nd.expand_dims(inputs, 0)\n",
    "        states = mx.nd.expand_dims(states, 0)\n",
    "\n",
    "        # Perform forward pass.\n",
    "        states, _ = self.rnn(inputs, [states])\n",
    "        outputs = self.decoder(states)\n",
    "\n",
    "        # Remove dummy dimensions\n",
    "        return outputs[0], states[0]\n",
    "\n",
    "    def forward_np(self, inputs: np.ndarray, states: np.ndarray) \\\n",
    "            -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Perform forward pass on numpy arrays. Only use during inference.\"\"\"\n",
    "        outputs, states = self.forward(mx.nd.array(inputs),\n",
    "                                       mx.nd.array(states))\n",
    "        return outputs.asnumpy(), states.asnumpy()\n",
    "\n",
    "    def freeze_weights(self):\n",
    "        \"\"\"Prevent weights of system to adapt.\"\"\"\n",
    "        self.collect_params().setattr('grad_req', 'null')\n",
    "\n",
    "    def get_state_init(self, asnumpy=False):\n",
    "        \"\"\"Return the initial states.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        asnumpy\n",
    "            Whether to return as numpy or mxnet array.\n",
    "        Returns\n",
    "        -------\n",
    "            Initial states of system (all zero).\n",
    "        \"\"\"\n",
    "        x = self.rnn.begin_state(1)[0][0]\n",
    "        if asnumpy:\n",
    "            return x.asnumpy()\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def A(self):\n",
    "        \"\"\"Dynamics matrix.\"\"\"\n",
    "        return self.rnn.h2h_weight.data().asnumpy()\n",
    "\n",
    "    @A.setter\n",
    "    def A(self, a):\n",
    "        self.rnn.h2h_weight.data()[:] = a\n",
    "\n",
    "    @property\n",
    "    def B(self):\n",
    "        \"\"\"Input matrix.\"\"\"\n",
    "        return self.rnn.i2h_weight.data().asnumpy()\n",
    "\n",
    "    @B.setter\n",
    "    def B(self, b):\n",
    "        self.rnn.i2h_weight.data()[:] = b\n",
    "\n",
    "    @property\n",
    "    def C(self):\n",
    "        \"\"\"Output matrix.\"\"\"\n",
    "        return self.decoder.weight.data().asnumpy()\n",
    "\n",
    "    @C.setter\n",
    "    def C(self, c):\n",
    "        self.decoder.weight.data()[:] = c\n",
    "\n",
    "\n",
    "class LQR:\n",
    "    \"\"\"A helper class to compute cost and control of LQR solution.\"\"\"\n",
    "    def __init__(self, environment: RNN, dt: float, q=0.5, r=0.5):\n",
    "        self.A = environment.A\n",
    "        self.B = environment.B\n",
    "        self.Q = np.eye(len(self.A)) * q * dt\n",
    "        self.R = np.eye(len(self.B.T)) * r * dt\n",
    "        self.K = self.get_gain()\n",
    "\n",
    "    def get_cost(self, x: np.ndarray, u: np.ndarray) -> np.ndarray:\n",
    "        return x.T @ self.Q @ x + u.T @ self.R @ u\n",
    "\n",
    "    def get_gain(self):\n",
    "        # Solution to the DARE\n",
    "        S = solve_discrete_are(self.A, self.B, self.Q, self.R)\n",
    "\n",
    "        # Feedback gain matrix\n",
    "        return (np.linalg.inv(self.B.T @ S @ self.B + self.R) @\n",
    "                self.B.T @ S @ self.A)\n",
    "\n",
    "    def get_control(self, x):\n",
    "        return -self.K @ x\n",
    "\n",
    "\n",
    "class LqrMx:\n",
    "    \"\"\"A helper class to compute the LQR loss as mxnet array.\"\"\"\n",
    "    def __init__(self, lqr: LQR):\n",
    "        self.Q = mx.nd.array(lqr.Q)\n",
    "        self.R = mx.nd.array(lqr.R)\n",
    "\n",
    "    def get_cost(self, x: NDArray, u: NDArray) -> NDArray:\n",
    "        return (mx.nd.dot(mx.nd.dot(x, self.Q), x) +\n",
    "                mx.nd.dot(mx.nd.dot(u, self.R), u))\n",
    "\n",
    "\n",
    "def evaluate_uncontrolled(\n",
    "        num_steps: int,\n",
    "        x_init: Tuple[float, float],\n",
    "        environment: RNN,\n",
    "        objective_function: Callable[[np.ndarray, np.ndarray], np.ndarray]) \\\n",
    "        -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Test performance of system when no control is applied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_steps\n",
    "        How many steps to take in environment during one episode.\n",
    "    x_init\n",
    "        Initial states of environment.\n",
    "    environment\n",
    "        The environment to be controlled.\n",
    "    objective_function\n",
    "        The LQR cost function used as evaluation metric.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Two arrays containing (for each time step):\n",
    "            - Environment states\n",
    "            - Costs\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    costs = []\n",
    "\n",
    "    x_environment = np.array(x_init)  # Initial state\n",
    "\n",
    "    for n in range(num_steps):\n",
    "        # Compute control.\n",
    "        u_environment = np.zeros(1)\n",
    "\n",
    "        # Compute lqr cost.\n",
    "        cost = objective_function(x_environment, u_environment)\n",
    "\n",
    "        # Take a step in environment.\n",
    "        y_environment, x_environment = environment.forward_np(u_environment,\n",
    "                                                              x_environment)\n",
    "\n",
    "        states.append(x_environment)\n",
    "        costs.append(cost)\n",
    "\n",
    "    return np.array(states), np.array(costs)\n",
    "\n",
    "\n",
    "def plot_variables(variables: dict, title: str):\n",
    "    for label, variable in variables.items():\n",
    "        plt.plot(variable, label=label)\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metrics(metrics: dict):\n",
    "    for label, metric in metrics.items():\n",
    "        plt.plot(metric, label=label)\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('LQR cost')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_curve(loss: np.ndarray, title: str):\n",
    "    plt.plot(loss)\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_grid(n=10, x_max=1, y_max=0.2) -> NDArray:\n",
    "    \"\"\"Create a rectangular 2d grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n\n",
    "        Number of grid nodes along each dimension.\n",
    "    x_max\n",
    "        Half the width of the grid (centered around zero).\n",
    "    y_max\n",
    "        Half the height of the grid (centered around zero).\n",
    "    \"\"\"\n",
    "\n",
    "    x_min, x_max = -x_max, x_max\n",
    "    y_min, y_max = -y_max, y_max\n",
    "    grid = np.mgrid[y_min:y_max:complex(0, n), x_min:x_max:complex(0, n)]\n",
    "    grid = grid[::-1]\n",
    "    grid = np.reshape(grid, (-1, n * n))\n",
    "    grid = np.transpose(grid)\n",
    "    return mx.nd.array(grid)\n",
    "\n",
    "\n",
    "def train_neuralsystem(\n",
    "        num_steps: int,\n",
    "        x_init: np.ndarray,\n",
    "        environment: RNN,\n",
    "        neuralsystem: RNN,\n",
    "        objective_function: Callable[[NDArray, NDArray], NDArray]) \\\n",
    "        -> np.ndarray:\n",
    "    \"\"\"Train the neural system by minimizing an objective function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_steps\n",
    "        How many steps to take in environment during one episode.\n",
    "    x_init\n",
    "        Initial states of environment. Shape [num_samples, num_states].\n",
    "    environment\n",
    "        The environment to control.\n",
    "    neuralsystem\n",
    "        The controller to train.\n",
    "    objective_function\n",
    "        The loss function to optimize. Must be compatible with mxnet arrays.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        1D array with average loss values for each epoch.\n",
    "    \"\"\"\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 5\n",
    "    trainer = mx.gluon.Trainer(neuralsystem.collect_params(), 'adam',\n",
    "                               {'learning_rate': learning_rate})\n",
    "    loss_training = []\n",
    "    for _ in trange(num_epochs, desc='epoch'):\n",
    "        loss_epoch = []\n",
    "        for x_environment in x_init:\n",
    "            x_neuralsystem = neuralsystem.get_state_init()\n",
    "            y_environment = x_environment\n",
    "            loss_sample = []\n",
    "            with autograd.record():\n",
    "                for n in range(num_steps):\n",
    "                    # Compute control.\n",
    "                    y_neuralsystem, x_neuralsystem = neuralsystem.forward(\n",
    "                        y_environment, x_neuralsystem)\n",
    "\n",
    "                    # Compute lqr cost.\n",
    "                    loss_sample.append(objective_function(x_environment,\n",
    "                                                          y_neuralsystem))\n",
    "\n",
    "                    # Take a step in environment.\n",
    "                    y_environment, x_environment = environment.forward(\n",
    "                        y_neuralsystem, x_environment)\n",
    "\n",
    "                loss_sample_mean = mx.nd.mean(mx.nd.concat(*loss_sample,\n",
    "                                                           dim=0))\n",
    "            loss_sample_mean.backward()\n",
    "            trainer.step(1)\n",
    "            loss_epoch.append(loss_sample_mean.asscalar())\n",
    "\n",
    "        loss_training.append(np.mean(loss_epoch))\n",
    "\n",
    "    return np.array(loss_training)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Environment (2 points)\n",
    "Here we create an environment for the agent (brain) to live in. We choose the double integrator dynamical system as environment (you may assume the noise-free and fully-observed case throughout this week's assignments). We want to be able to differentiate through the environment. You already implemented a differentiable version of the double integrator in assignment 8 using jax. Here we suggest to use the mxnet implementation provided above to simplify training the neural system and prosthesis later. So:\n",
    "- **Create the double integrator environment as a recurrent neural network**. (Hint: The weights do not have to be learned but can be set directly using the state equations.)\n",
    "- **Create an LQR controller** to solve the particle stabilization in the RNN environment. **Verify that the dynamics of the closed system match** the ones you found in assignment 6. Compare against the uncontrolled case. (Hint: Create a new function \"evaluate_optimal\" based on the \"evaluate_uncontrolled\" function above to get the dynamics of the closed system.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Neural system (4 points)\n",
    "Now we add a brain to interact with the environment. The brain replaces the optimal LQR controller above to perform the particle stabilization task.\n",
    "- **Implement the neural system as an RNN**. (Hint: Use about 30-50 neurons for the hidden layer. The other dimensions are determined via the interaction with the environment.)\n",
    "- **Define a suitable objective function** to train the neural system.\n",
    "- **Train the neural system.** (Hint: Use one of the helper functions above to create a dataset of initial values for the states.) Make sure the environment weights are frozen while training the brain.\n",
    "- **Compare the result** against the uncontrolled and optimal LQR baselines. (Hint: Create a new function \"evaluate_neuralsystem\" based on the \"evaluate_optimal\" function you implemented above.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prosthesis (4 points)\n",
    "Now that we have a functional brain model, we can perturb it and try to restore its functionality by adding a prosthesis.\n",
    "- **Implement a perturbation of the neural system**, e.g. by setting some rows of the sensory synapses to zero. (Use a perturbation strength that makes the performance degrade notably, but not destroy it completely, e.g. lesion 80% of the sensory synapses.) Evaluate the perturbed neural system and compare against the results above.\n",
    "- **Create a prosthesis RNN.** (Hint: A hidden population of about 40 neurons works well.)\n",
    "- **Train the prosthesis** by connecting it to the association population and minimizing the objective function as before. (Hint: Create a new function \"train_prosthesis\" based on \"train_neuralsystem\" above.) Remember to freeze the neural system parameters before training the prosthesis.\n",
    "- **Verify that the performance is restored.** (Hint: Create a new function \"evaluate_prosthesis\" based on the \"evaluate_neuralsystem\" function you implemented above.)\n",
    "- Optional: Play around with different kinds of perturbation / prostheses models / learning rules (e.g. RL)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define and apply perturbation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
